\begin{abstract}
  Digital video retrieval, filtering and reconfiguration are difficult tasks to solve using current computational techniques. An important cause of this difficulty is the semantic gap between a visual representation and the meaning we address to it. A solution commonly sought in AI research is to reduce the gap by visual analysis and the linking thereof to previously established symbolic representations of semantical concepts. These methods often perform poorly on unpredictable content found in the large video libraries of user generated content that account for much of the global internet traffic these days.
  A second way of hunting down meaning in visual content is to step over the gap altogether and ask people directly for a meaningful interpretation one wishes to acquire for an item of content. By accessing many people's interpretations in small bite-sized tasks, collectively grounded annotations can be established. This form of accessing human computational power has seen a major increase in attention and application, for a large part because of the increased connectivity of individuals to the web.
  This thesis investigates how tasks involving meaningful interpretation of video content can benefit from the use of human computation. In order to test the validity of these approaches `wePorter' is developed, a system with the purpose of finding local intervals of interest within videos in a larger set of topically related content. We also investigate how such a system can be used for reconfiguration of content into new and informative stories.
  [concluding]
\end{abstract}
\pagebreak 
