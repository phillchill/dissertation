\chapter{Introduction}
\label{ch:introduction}

% specific example visual information overload
Someone looking to get a feel of a recent large-scale event, might turn to an online video platform where it is common practice for users to share videos of their recent experiences\cite{Cha:2007ty,Cheng:2007tc}. Querying the video platform YouTube for ``Burning Man 2012, this month'' for example, returns a set of several thousand videos\cite{youtubeBM}. `Burning Man' is a participatory festival in the Nevada desert that attracts over 50,000 attendees\footnote{\url{http://www.huffingtonpost.com/2012/09/02/burning-man-2012-attendan_n_1851087.html}}. The festival's participants not only collaboratively create  a week long festival, but as the query shows, also record plenty of videos documenting their activities. With so much content to offer it becomes a challenging task to find a set of videos that collectively give an overview of the atmosphere at an event.

% general context, video is booming
The video platform YouTube has grown incredibly fast since its launch in 2005 and accounts for a large part online traffic\cite{Cheng:2007tc}. The amount of user-generated video content that is uploaded to YouTube is increasing to incredible proportions, but it is not just YouTube that enjoys a heightened popularity. Online video is booming and the increase in available content along with vast numbers of users sharing, searching and otherwise interacting with video online, demand effective methods for video analysis.

% semantic gap
When regarding visual content, people perceive high-level semantical concepts that contribute to their overall understanding of the depicted material. Computers on the other hand commonly only have access to low-level features extracted from the digital content by data-driven techniques. It is hard to for these computational methods to address the high-level conceptual interpretations perceived by humans. This discrepancy between low-level features and high-level semantical concepts is known as the `semantic gap'\cite{Smeulders:2000tx} and poses fundamental challenges for computational approaches to visual interpretation.

% challenge for video
Users engaged in tasks like video search are used to phrasing their queries in terms of semantical concepts. Even when content-based retrieval methods like `query-by-example' are used, users are known to expect semantic similarity between different pieces of content, rather than similarity based on low-level features that is used by these methods\cite{Worring:2007vm, Snoek:jf, Hollink:2005ei}. These issues present fundamental challenges in computational approaches to video interpretation. Because the difficulties are inherent to the computational approaches that are currently employed in attempt to narrow the semantic gap, it might be an option to look at other solutions to the bridge the gap.

% enter HC
Recent years have seen much enthusiasm for a new paradigm in computer science that is undoubtedly stimulated by the expanded connectivity to and increased functionality of web-based applications. The idea in `human computation' is to combine the computational powers of humans and and computers to solve problems that are hard to conquer by digital computation alone\cite{vonAhn:2005wi}. Human computation seems particularly apt for application to the medium of (online) video because of the different levels of semantical interpretations humans perceive in videos. Furthermore, the interactive online video applications prevalent on the internet may prove useful entry points for accessing human computational powers.

% wePorter
To explore the merit of human computational approaches, this thesis presents a human computation system with the purpose of finding interesting segments within videos and reconfiguring these into meaningful overview stories. We present an interface that uses implicit user feedback in the form of attention time captured during the presentation of two video segments in parallel. We use the interaction data thus acquired to make predictions of global interest in parts of videos and propose a framework for attention-based filtering of video content. Besides the implicit acquisition of users' attentional data, the framework is able to reconfigure segmented content based on analyses of the data. The system is evaluated in a series of user experiments aimed to show whether the filtering techniques indeed provide a distinction of content that correlates with user interest.

% overview
The thesis is structured as follows. The next chapter indicates fundamental challenges faced in tasks concerning computational video interpretation. We describe current methods to solve the problem and indicate why they are not satisfactory for the wide domain of user generated video content that accounts for unprecedented amounts of data and traffic on the web. In chapter \ref{ch:human_computation} the idea of human computation is introduced and hinted to as a possible solution for the challenges in meaningful video analysis. Chapter \ref{ch:weporter} presents `wePorter', a human computation system that uses interaction data for meaningful interest-based filtering and reconfiguration of video segments. We report on the results of a series of experiments run on the wePorter system in chapter \ref{ch:evaluation}. A discussion of the work is included in chapter \ref{ch:discussion} along with a word on future directions. Finally, conclusions are presented in chapter \ref{ch:conclusions}.


