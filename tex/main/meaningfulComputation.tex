\chapter{The Quest for Meaning in Video}
\label{ch:quest}

\section{Forms of Meaning in Film and Video}

\subsection{Meaning in Visuals}
\cite{Bruno:2002tt}

\subsection{Meaning in Concept}
\subsection{Meaning in Structure}
[cite bordwell \& Thompson: analysis of context dependency]

\subsection{Meaning in Annotations}
\cite{Kuwano:2000wy}

\section{Computational Undertakings of the Quest}

\subsection{Steps towards Meaning: An Overview}

Schematized summary of different steps:
indexing
automatic metadata
annotating
  Human-Driven Labeling
  Machine-Driven Labeling
multimodal feature fusion
  


\subsection{Indexing to enable search}
Because visual data on it's own provides little machine-readable handles to search and find, repositories of multi-media content need to be index to enable search. Within the task of video indexing several approaches are taken 


\section{collaborative filtering}
Information filtering agents and collaborative filtering both
attempt to alleviate information overload by identifying
which items a user will find worthwhile.  I