\chapter{The Quest for Meaning in Video}
\label{ch:quest}





\section{The Need for Labeling}

Whereas textual data can be searched relatively easily because of its symbolic nature, this is more difficult for video. Because visual data on it's own provides little machine-readable handles to search for, repositories of multimedia content need to be indexed with symbolic labels to enable search and retrieval. 


\subsection{Human Labelling}

\subsection{Machine Labelling}


\section{The Semantic Gap}


\section{Computationally Narrowing the Gap}

\subsection{Supervised Concept Learning}

The paradigm most in use for the detection of concepts in video is supervised learning. In a supervised machine learning task, one learns the relation between a collection of input values and a smaller set of output values. A relation between inputs and outputs is learned by presenting a large number of training examples as input along with their respective output values. For video concept detection, input values are usually a collection of features representing different aspects of the video while outputs code for the concept that is known to be present. 

Although detectors can be trained to learn to detect patters of multiple concepts, usually a separate concept detectors are trained for distinct concepts. By applying multiple detectors on an previously unseen input instance, multiple concepts can be detected.

\subsection{Video Feature Extraction}

\subsubsection{Meaning in Visual Features}

Visual features are extracted both locally at the level of regions and pixels and globally at the level of frames.

\paragraph{Color}

\paragraph{Texture}

\paragraph{Shape}

\subsubsection{Meaning in other Modalities}
The use of audio and text for extraction of features.

[Telop-on-demand: Video structuring and retrieval based on text recognition]\cite{Kuwano:2000wy}
[Addressing the Challenge of Visual Information Access from Digital Image and Video Libraries]\cite{Christel:2005td}

\subsection{Meaning in Structure}


[cite bordwell \& Thompson: analysis of context dependency]
[link to narratives and storytelling]
% hypervideo as form of 1 narrative 2 navigation, link to database documentary
[HyperCafe: Narrative and Aesthetic Properties of Hypervideo \cite{Sawhney:1996tk}]

\subsubsection{Spatial Structure}
\subsubsection{Temporal Structure}




\section{Interactive Storytelling: From database to data-based}
\label{ch:storytelling}
\subsection{Symbolic approaches}
\label{sec:symbolic}

\cite{Vilmos:2011wv,RodrigoLaiolaGuimaraes:2011tl,Ursu:2009gc}

\subsection{Statistic approaches}
\label{sec:statistic}

\subsection{Remixing}

The reconfiguration of smaller units that carry meaning within themselves is common practice for textual media such as blogs, where it is easy to quote part of  another author`s writing in a new post [ref]. 

It needs to be said that some reconfiguration of videos is taking place, but even though it often concerns content that was originally sourced online, much of the creative act of remixing happens offline.


\subsection{Taking the remix online}

examples like: Aaron Koblin (johnny cash project, exquisite corps, etc)

there is even word of a true remix culture\cite{Diakopoulos:2007tl}.

the availability of multimedia content via the internet has meant a surge in 


\section{Computational Difficulties}

% problem is that no CV algorithms perform reliable AND generally

% the problem of acquiring labelled data for ML approaches
% problem of keeping ML techniques up to date in a dynamical environment where new content is added every minute (and a lot of it as we will see when we discuss user generated online video)





