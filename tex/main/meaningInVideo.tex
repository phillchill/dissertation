\chapter{The Quest for Meaning in Video}
\label{ch:quest}

 

The intention of this thesis is not to give an accurate explanation of daunting concepts like meaning or semantics, nor is it to give an in-depth description of the diverse work on the relationship between signifier and signified in the field of semiotics. This first chapter is meant to briefly introduce the difficulties that current computational methods have in arriving at a meaningful interpretation of visual content. To this purpose we formulate a framework of computational analyses of meaning that serves to establish terminology to work with, rather than to make claims about the internal functioning of human understanding or signifying systems.

\section{Computational Undertakings of the Quest for Meaning}

\subsection{Meaning in Visuals}
[Video structuring, indexing and retrieval based on global motion wavelet coefficients]\cite{Bruno:2002tt}

\subsection{Meaning in Concept}
\subsection{Meaning in Structure}
[cite bordwell \& Thompson: analysis of context dependency]
% hypervideo as form of 1 narrative 2 navigation, link to database documentary
[HyperCafe: Narrative and Aesthetic Properties of Hypervideo \cite{Sawhney:1996tk}]

\subsection{Meaning in Annotations}
[Telop-on-demand: Video structuring and retrieval based on text recognition]\cite{Kuwano:2000wy}
[Addressing the Challenge of Visual Information Access from Digital Image and Video Libraries]\cite{Christel:2005td}

\section{Computational Undertakings of the Quest}
\subsection{The Semantic Gap}


\subsection{Steps towards Meaning: An Overview}
Schematized summary of different steps:
indexing
automatic metadata
annotating
  Human-Driven Labeling
  Machine-Driven Labeling
multimodal feature fusion
concept based
content based [Relevance feedback: A power tool for interactive content-based image retrieval]\cite{Rui:1998uj}
[The Relative Effectiveness of Concept-based Versus Content-based Video Retrieval]\cite{Yang:2004tc}

[collaborative filtering] \url{http://en.wikipedia.org/wiki/Collaborative_filtering}

\subsection{Indexing to enable search}
Because visual data on it's own provides little machine-readable handles to search and find, repositories of multimedia content need to be index to enable search. Within the task of video indexing several approaches are taken 

\section{Computational Difficulties}

% problem is that no CV algorithms perform reliable AND generally

% the problem of acquiring labelled data for ML approaches
% problem of keeping ML techniques up to date in a dynamical environment where new content is added every minute (and a lot of it as we will see when we discuss user generated online video)





